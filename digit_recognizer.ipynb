{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRKUkvP3T6kd",
        "outputId": "198e6bde-2c96-4c22-c4a4-a974b93fa109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Pytorch import\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "from torch import nn\n",
        "\n",
        "DATA_PATH = '/path/to/data/'\n",
        "\n",
        "# Get device\n",
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nT0bAvUrBYdH"
      },
      "outputs": [],
      "source": [
        "# Read the training data\n",
        "df = pd.read_csv(DATA_PATH + 'train.csv')\n",
        "labels = df['label']\n",
        "training_images = df.drop('label', axis=1)\n",
        "\n",
        "# Create a custom Dataset class for PyTorch\n",
        "class DigitDataset(Dataset):\n",
        "    def __init__(self, csv_path, transform=None, target_transform=None):\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        self.data = pd.read_csv(csv_path)\n",
        "        self.is_train_data = 'label' in self.data.columns\n",
        "        self.features = self.data.drop('label', axis=1) if self.is_train_data else self.data\n",
        "        self.labels = self.data['label'] if self.is_train_data else None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pixels = self.features.iloc[idx].to_numpy(dtype=np.uint8)\n",
        "        label = int(self.labels.iloc[idx]) if self.is_train_data else None\n",
        "\n",
        "        img = pixels.reshape(28, 28)\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return img, label if self.is_train_data else img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dr3vyVm8vDLT"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter setups\n",
        "learning_rate = 1e-3\n",
        "epochs = 30\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "EAQB_AcUIcGG",
        "outputId": "4fd4d05e-bac1-43f4-f9f3-bf441101ca59"
      },
      "outputs": [],
      "source": [
        "# Initialize dataset\n",
        "full_training_data = DigitDataset(\n",
        "    DATA_PATH + 'train.csv',\n",
        "    transform=ToTensor())\n",
        "\n",
        "train_size = int(0.8 * len(full_training_data))\n",
        "test_size = len(full_training_data) - train_size\n",
        "train_dataset, test_dataset = random_split(full_training_data, [train_size, test_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=2)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=2)\n",
        "\n",
        "# Iterate through dataset and see some samples\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "\n",
        "# Show some sample data points\n",
        "figure = plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    img = train_features[i].squeeze()\n",
        "    label = torch.argmax(train_labels[i]).item()\n",
        "\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(label)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDb0Za8jNszX",
        "outputId": "97f6792e-84bb-48f4-e7c6-26115c7bc557"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DigitNet(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class DigitNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = DigitNet().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "5LF8ZVWzOvms"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X = X.to(device, non_blocking=True)\n",
        "        y = torch.as_tensor(y, device=device, dtype=torch.long)\n",
        "\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = X.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(dim=1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-jP1nC4wWiB",
        "outputId": "41b42183-0ac4-4a9c-9c25-dd9bb4a86148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.000711  [   64/33600]\n",
            "loss: 0.004382  [ 6464/33600]\n",
            "loss: 0.000029  [12864/33600]\n",
            "loss: 0.000149  [19264/33600]\n",
            "loss: 0.015674  [25664/33600]\n",
            "loss: 0.000474  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 97.5%, Avg loss: 0.174493 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.000024  [   64/33600]\n",
            "loss: 0.003685  [ 6464/33600]\n",
            "loss: 0.189161  [12864/33600]\n",
            "loss: 0.000004  [19264/33600]\n",
            "loss: 0.000176  [25664/33600]\n",
            "loss: 0.000036  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 98.0%, Avg loss: 0.134618 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.000001  [   64/33600]\n",
            "loss: 0.000003  [ 6464/33600]\n",
            "loss: 0.000001  [12864/33600]\n",
            "loss: 0.003458  [19264/33600]\n",
            "loss: 0.000002  [25664/33600]\n",
            "loss: 0.007344  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 97.9%, Avg loss: 0.140605 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.006083  [   64/33600]\n",
            "loss: 0.000007  [ 6464/33600]\n",
            "loss: 0.000533  [12864/33600]\n",
            "loss: 0.000101  [19264/33600]\n",
            "loss: 0.091408  [25664/33600]\n",
            "loss: 0.000288  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 97.6%, Avg loss: 0.150490 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.000017  [   64/33600]\n",
            "loss: 0.000330  [ 6464/33600]\n",
            "loss: 0.000178  [12864/33600]\n",
            "loss: 0.000662  [19264/33600]\n",
            "loss: 0.002150  [25664/33600]\n",
            "loss: 0.053266  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 97.7%, Avg loss: 0.141945 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.000046  [   64/33600]\n",
            "loss: 0.001624  [ 6464/33600]\n",
            "loss: 0.010169  [12864/33600]\n",
            "loss: 0.003759  [19264/33600]\n",
            "loss: 0.068836  [25664/33600]\n",
            "loss: 0.004952  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 98.0%, Avg loss: 0.120726 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.000003  [   64/33600]\n",
            "loss: 0.000030  [ 6464/33600]\n",
            "loss: 0.000214  [12864/33600]\n",
            "loss: 0.014714  [19264/33600]\n",
            "loss: 0.029733  [25664/33600]\n",
            "loss: 0.028832  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 97.8%, Avg loss: 0.137313 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.001506  [   64/33600]\n",
            "loss: 0.001359  [ 6464/33600]\n",
            "loss: 0.000032  [12864/33600]\n",
            "loss: 0.024110  [19264/33600]\n",
            "loss: 0.009225  [25664/33600]\n",
            "loss: 0.000087  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.125246 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.000023  [   64/33600]\n",
            "loss: 0.000053  [ 6464/33600]\n",
            "loss: 0.000134  [12864/33600]\n",
            "loss: 0.000084  [19264/33600]\n",
            "loss: 0.000182  [25664/33600]\n",
            "loss: 0.000052  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 98.0%, Avg loss: 0.127306 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.000026  [   64/33600]\n",
            "loss: 0.000133  [ 6464/33600]\n",
            "loss: 0.001552  [12864/33600]\n",
            "loss: 0.000127  [19264/33600]\n",
            "loss: 0.020183  [25664/33600]\n",
            "loss: 0.000002  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 97.7%, Avg loss: 0.151984 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.000191  [   64/33600]\n",
            "loss: 0.000000  [ 6464/33600]\n",
            "loss: 0.000121  [12864/33600]\n",
            "loss: 0.000276  [19264/33600]\n",
            "loss: 0.000006  [25664/33600]\n",
            "loss: 0.000027  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 98.1%, Avg loss: 0.113942 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.000009  [   64/33600]\n",
            "loss: 0.000021  [ 6464/33600]\n",
            "loss: 0.000969  [12864/33600]\n",
            "loss: 0.000022  [19264/33600]\n",
            "loss: 0.000006  [25664/33600]\n",
            "loss: 0.007876  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.122990 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.000013  [   64/33600]\n",
            "loss: 0.000002  [ 6464/33600]\n",
            "loss: 0.000137  [12864/33600]\n",
            "loss: 0.000014  [19264/33600]\n",
            "loss: 0.002118  [25664/33600]\n",
            "loss: 0.000132  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 98.1%, Avg loss: 0.138901 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.000058  [   64/33600]\n",
            "loss: 0.000000  [ 6464/33600]\n",
            "loss: 0.000036  [12864/33600]\n",
            "loss: 0.000101  [19264/33600]\n",
            "loss: 0.000024  [25664/33600]\n",
            "loss: 0.037265  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 97.2%, Avg loss: 0.176114 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.025871  [   64/33600]\n",
            "loss: 0.000518  [ 6464/33600]\n",
            "loss: 0.000215  [12864/33600]\n",
            "loss: 0.027641  [19264/33600]\n",
            "loss: 0.000016  [25664/33600]\n",
            "loss: 0.000173  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 97.9%, Avg loss: 0.145849 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.000314  [   64/33600]\n",
            "loss: 0.004398  [ 6464/33600]\n",
            "loss: 0.000011  [12864/33600]\n",
            "loss: 0.000005  [19264/33600]\n",
            "loss: 0.003798  [25664/33600]\n",
            "loss: 0.009741  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 97.9%, Avg loss: 0.138282 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.002902  [   64/33600]\n",
            "loss: 0.002093  [ 6464/33600]\n",
            "loss: 0.000176  [12864/33600]\n",
            "loss: 0.000001  [19264/33600]\n",
            "loss: 0.007019  [25664/33600]\n",
            "loss: 0.047150  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.146511 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.000104  [   64/33600]\n",
            "loss: 0.000002  [ 6464/33600]\n",
            "loss: 0.000002  [12864/33600]\n",
            "loss: 0.000328  [19264/33600]\n",
            "loss: 0.000758  [25664/33600]\n",
            "loss: 0.002299  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 97.9%, Avg loss: 0.157450 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.016032  [   64/33600]\n",
            "loss: 0.000003  [ 6464/33600]\n",
            "loss: 0.000204  [12864/33600]\n",
            "loss: 0.000065  [19264/33600]\n",
            "loss: 0.000000  [25664/33600]\n",
            "loss: 0.000000  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.128163 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.003296  [   64/33600]\n",
            "loss: 0.000003  [ 6464/33600]\n",
            "loss: 0.000131  [12864/33600]\n",
            "loss: 0.007163  [19264/33600]\n",
            "loss: 0.000143  [25664/33600]\n",
            "loss: 0.000004  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 97.7%, Avg loss: 0.173079 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.007557  [   64/33600]\n",
            "loss: 0.001327  [ 6464/33600]\n",
            "loss: 0.000382  [12864/33600]\n",
            "loss: 0.000247  [19264/33600]\n",
            "loss: 0.000000  [25664/33600]\n",
            "loss: 0.000175  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 97.7%, Avg loss: 0.170452 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.003834  [   64/33600]\n",
            "loss: 0.000074  [ 6464/33600]\n",
            "loss: 0.000011  [12864/33600]\n",
            "loss: 0.000001  [19264/33600]\n",
            "loss: 0.000128  [25664/33600]\n",
            "loss: 0.000018  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 97.9%, Avg loss: 0.173786 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.002154  [   64/33600]\n",
            "loss: 0.000005  [ 6464/33600]\n",
            "loss: 0.000190  [12864/33600]\n",
            "loss: 0.000511  [19264/33600]\n",
            "loss: 0.000021  [25664/33600]\n",
            "loss: 0.000002  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 98.0%, Avg loss: 0.138122 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.000001  [   64/33600]\n",
            "loss: 0.000000  [ 6464/33600]\n",
            "loss: 0.000007  [12864/33600]\n",
            "loss: 0.000000  [19264/33600]\n",
            "loss: 0.000523  [25664/33600]\n",
            "loss: 0.000977  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 98.0%, Avg loss: 0.167215 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.000071  [   64/33600]\n",
            "loss: 0.000009  [ 6464/33600]\n",
            "loss: 0.000000  [12864/33600]\n",
            "loss: 0.000258  [19264/33600]\n",
            "loss: 0.001064  [25664/33600]\n",
            "loss: 0.000003  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 98.0%, Avg loss: 0.140391 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.000002  [   64/33600]\n",
            "loss: 0.000002  [ 6464/33600]\n",
            "loss: 0.000003  [12864/33600]\n",
            "loss: 0.000008  [19264/33600]\n",
            "loss: 0.000250  [25664/33600]\n",
            "loss: 0.006399  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 98.1%, Avg loss: 0.143844 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.000093  [   64/33600]\n",
            "loss: 0.000001  [ 6464/33600]\n",
            "loss: 0.000364  [12864/33600]\n",
            "loss: 0.000027  [19264/33600]\n",
            "loss: 0.000001  [25664/33600]\n",
            "loss: 0.000011  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 97.8%, Avg loss: 0.166366 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.000204  [   64/33600]\n",
            "loss: 0.000003  [ 6464/33600]\n",
            "loss: 0.000000  [12864/33600]\n",
            "loss: 0.000092  [19264/33600]\n",
            "loss: 0.000001  [25664/33600]\n",
            "loss: 0.000001  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 97.8%, Avg loss: 0.173046 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.000766  [   64/33600]\n",
            "loss: 0.000473  [ 6464/33600]\n",
            "loss: 0.096412  [12864/33600]\n",
            "loss: 0.000007  [19264/33600]\n",
            "loss: 0.000001  [25664/33600]\n",
            "loss: 0.000004  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.142117 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.000001  [   64/33600]\n",
            "loss: 0.000001  [ 6464/33600]\n",
            "loss: 0.000001  [12864/33600]\n",
            "loss: 0.000201  [19264/33600]\n",
            "loss: 0.001076  [25664/33600]\n",
            "loss: 0.000000  [32064/33600]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.138248 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnYn-ugZ2OFO",
        "outputId": "1fb60f9b-704c-43e6-9d9d-a15c9321585b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved submission\n"
          ]
        }
      ],
      "source": [
        "kaggle_dataset = DigitDataset(\n",
        "    DATA_PATH + 'test.csv',\n",
        "    transform=ToTensor())\n",
        "\n",
        "kaggle_dataloader = DataLoader(kaggle_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Make predictions\n",
        "model.eval()\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X, y in kaggle_dataloader:\n",
        "        X = X.to(device)\n",
        "        outputs = model(X)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "\n",
        "# Save submission\n",
        "submission = pd.DataFrame({\n",
        "    'ImageId': range(1, len(predictions) + 1),\n",
        "    'Label': predictions\n",
        "})\n",
        "\n",
        "submission.to_csv(DATA_PATH + 'submission.csv', index=False)\n",
        "print('Saved submission')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
